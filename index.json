[{"authors":null,"categories":null,"content":"I am a second-year master student at University of Electronic Science and Technology of China (UESTC), Chengdu, China. I am supervised by Prof. Yan Chen and my research interest is about computer vision and computational imaging, especially on Non-line-of-sight(NLOS) imaging.\nI received my Bachelor of Engineering Degree at UESTC in 2019.\n  Download my resumé or 简历\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a second-year master student at University of Electronic Science and Technology of China (UESTC), Chengdu, China. I am supervised by Prof. Yan Chen and my research interest is about computer vision and computational imaging, especially on Non-line-of-sight(NLOS) imaging.","tags":null,"title":"Ruixu Geng (耿瑞旭)","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://ruixu.netlify.app/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Ruixu Geng","Yang Hu","Zhi Lu","Cong Yu","Houqiang Li","Yan Chen"],"categories":null,"content":"","date":1616639170,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616639170,"objectID":"83a523c42332f6810173728dc7995190","permalink":"https://ruixu.netlify.app/publication/a-paper-about-passive-nlos-imaging/","publishdate":"2021-03-25T02:26:10.244Z","relpermalink":"/publication/a-paper-about-passive-nlos-imaging/","section":"publication","summary":"","tags":["NLOS imaging","image restoration","deep learning","computational periscopy"],"title":"A paper about passive NLOS imaging","type":"publication"},{"authors":["Yijun Liu","Zhengning Wang","Ruixu Geng","Hao Zeng","Yi Zeng"],"categories":null,"content":"","date":1616637783,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616637783,"objectID":"2c1f96d01ee5940873576dfdc92771fa","permalink":"https://ruixu.netlify.app/publication/structure-preserving-extremely-low-light-image-enhancement-with-fractional-order-differential-mask-guidance/","publishdate":"2021-03-25T02:03:03.072Z","relpermalink":"/publication/structure-preserving-extremely-low-light-image-enhancement-with-fractional-order-differential-mask-guidance/","section":"publication","summary":"","tags":["Image Enhancement"],"title":"Structure-Preserving Extremely Low Light Image Enhancement with Fractional Order Differential Mask Guidance","type":"publication"},{"authors":null,"categories":null,"content":"Passive NLOS imaging is an extremely pathological problem. This project aims to complete data-driven passive NLOS imaging through deep learning. The proposed algorithm can make use of previously underutilized scene priors, thereby improving the effect of passive NLOS imaging.\nWe also collected a data set with more than 3,000,000 samples, hoping to alleviate the problem of insufficient data set faced by NLOS imaging. After all, the performance of the supervised algorithm depends to a large extent on the quality of the dataset.\nThis project has been submitted to a journal.\n","date":1603607311,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603607311,"objectID":"d5baea11669ca7013b8d8f14d377e242","permalink":"https://ruixu.netlify.app/project/passive-nlos-imaging-based-on-menifold-embedding/","publishdate":"2020-10-25T06:28:31.806Z","relpermalink":"/project/passive-nlos-imaging-based-on-menifold-embedding/","section":"project","summary":"Use data-driven algorithms to improve the quality of passive NLOS imaging","tags":["Passive imaging","NLOS imaging","Autoencoder","Optimal transport","Feature learning"],"title":"Passive NLOS imaging based on menifold embedding","type":"project"},{"authors":null,"categories":null,"content":"In mid-2018, under the guidance of our mentor, we plan to follow the work of Stanford University O\u0026rsquo;Toole and others on time-resolved NLOS imaging\n M. O’Toole, D. B. Lindell, and G. Wetzstein, “Confocal non-line-of-sight imaging based on the light-cone transform,” Nature, vol. 555, no. 7696, p. 338, 2018, doi: https://doi.org/10.1038/nature25489.\n We purchased corresponding equipment, including ultrafast pulse lasers, single-photon avalanche diodes, time-dependent single-photon counters, etc., and purchased an optical platform.\nAlthough our laboratory does not have a basis for optical experiments, we have established a confocal NLOS imaging system. This system can currently image some simple NLOS scenes, but there is still a problem of large time jitter (which means a low horizontal resolution). At present, we are trying our best to improve the reconstruction quality from both perspective of hardware and algorithm.\n","date":1579927286,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579927286,"objectID":"e2b318576e030edf8dd1446be18700ce","permalink":"https://ruixu.netlify.app/project/build-confocal-nlos-imaging-platform/","publishdate":"2020-01-25T04:41:26.771Z","relpermalink":"/project/build-confocal-nlos-imaging-platform/","section":"project","summary":"NLOS imaging system modeled on the confocal setting proposed by O'Toole et al.","tags":["NLOS imaging","TCSPC","Light"],"title":"Build Confocal NLOS Imaging platform ","type":"project"},{"authors":null,"categories":null,"content":"This project is my undergraduate graduation project, its summary is as follows\n Non-line-of-sight imaging technology that can image objects outside the field of view has important application prospects in many fields, such as security and automatic driving. Traditional non-line-of-sight imaging studies usually use an imaging model to model the data acquisition process and reconstruct the hidden scene by solving the imaging model. At present, traditional imaging models is not accurate enough so that they can only reconstruct a simple hidden scene. In addition, traditional reconstruction algorithms have a long reconstruction time and are difficult to apply in real time applications.\n  In order to overcome the shortcomings of traditional imaging and improve the reconstruction speed, this paper proposes a three-dimensional reconstruction algorithm for non-line-of-sight imaging based on deep learning. The reconstruction algorithm firstly obtains 30,000 simulation data as a dataset by simulating existed imaging model. Then, we build, train and test a reconstructing algorithm based on deep learning using the conditional GAN with similar results to traditional reconstruction algorithms. Through contrast experiments, it is concluded that the deep learning-based reconstruction algorithm is more robust to parameter correction errors and can effectively reduce the high dependence on parameter calibration. In addition, based on deep learning, the reconstruction algorithm only needs 20ms to reconstruct a single hidden scene, while the traditional algorithm requires at least 0.2s. Therefore, the reconstruction algorithm based on deep learning can greatly improve the reconstruction speed of non-line-of-sight imaging. Finally, this paper analyzes the shortcomings and improvement schemes of the proposed non-line-of-sight imaging algorithm based on deep learning.\n However, this project failed to take into account the noise caused by the SPAD sensor, so it failed to achieve good results on the public data. Chopite et al.\u0026rsquo;s work in CVPR 2020 has achieved good results using U-Net:\n J. G. Chopite, M. B. Hullin, M. Wand, and J. Iseringhausen, “Deep Non-Line-of-Sight Reconstruction,” 2020.\n ","date":1569395412,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569395412,"objectID":"3f8053b1f7878e81b1d59d8d91070b9f","permalink":"https://ruixu.netlify.app/project/time-resolved-non-line-of-sight-imaging-algorithm-based-on-gan/","publishdate":"2019-09-25T07:10:12.824Z","relpermalink":"/project/time-resolved-non-line-of-sight-imaging-algorithm-based-on-gan/","section":"project","summary":"Use GAN to complete data-driven active non-line-of-sight imaging","tags":["GAN","Deep Learning","NLOS imaging","Optics","Active Imaging"],"title":"Time-resolved NLOS imaging algorithm based on GAN","type":"project"},{"authors":null,"categories":null,"content":"Blood products have high requirements for storage conditions, and how to quickly complete the transportation of blood products is a challenging problem. In this project, we aimed at the UAV blood transportation scenario, taking Oxfordshire as the scope, comprehensively considering multiple influencing factors such as law, environment, and population, and evaluated the feasibility of using UAVs to complete the transportation of blood products.\nThis project was completed at Oxford University.\n ","date":1566714569,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1566714569,"objectID":"b8474ef9ea60fbf7be1b334f246c4e6b","permalink":"https://ruixu.netlify.app/project/route-planning-for-oxfordshire-uav-blood-transport/","publishdate":"2019-08-25T06:29:29.262Z","relpermalink":"/project/route-planning-for-oxfordshire-uav-blood-transport/","section":"project","summary":"Explore the feasibility of using drones to transport blood products","tags":["Shortest path"],"title":"Route planning for Oxfordshire UAV blood transport ","type":"project"},{"authors":["Ruixu Geng"],"categories":[],"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1559347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559347200,"objectID":"ff6a19061a984819d30c916886db56ef","permalink":"https://ruixu.netlify.app/publication/example/","publishdate":"2019-06-01T00:00:00Z","relpermalink":"/publication/example/","section":"publication","summary":"This thesis synthesizes NLOS dataset by rendering (based on LCT proposed by O'Toole et al.), and then reconstructs it by GAN (modified from DeblurGAN).","tags":["NLOS imaging","GAN","deep learning","transient imaging"],"title":"Active NLOS imaging based on deep learning","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot;\rif porridge == \u0026quot;blueberry\u0026quot;:\rprint(\u0026quot;Eating...\u0026quot;)\r  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}}\r{{% fragment %}} **Two** {{% /fragment %}}\r{{% fragment %}} Three {{% /fragment %}}\r Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}}\r- Only the speaker can read these notes\r- Press `S` key to view\r{{% /speaker_note %}}\r Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}}\r{{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}}\r{{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}\r  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1,\r.reveal section h2,\r.reveal section h3 {\rcolor: navy;\r}\r  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://ruixu.netlify.app/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Ruixu GENG","Diyuan Wu","Guangxu YANG","Guanghui CHENG"],"categories":null,"content":"","date":1537840564,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537840564,"objectID":"b4cb3367dc27327f0c9aae402f29eae0","permalink":"https://ruixu.netlify.app/publication/parameters-calibration-and-imaging-for-ct-system/","publishdate":"2018-09-25T01:56:04.059Z","relpermalink":"/publication/parameters-calibration-and-imaging-for-ct-system/","section":"publication","summary":"","tags":["reconstruction","CT"],"title":"Parameters Calibration and Imaging for CT System","type":"publication"},{"authors":null,"categories":null,"content":"We connect a temperature and humidity sensor to the Arduino, which can measure the current ambient temperature and humidity and transmit the data to the cloud in real time. When it is detected that the temperature and humidity meet the irrigation requirements, the valve is controlled to release water and a reminder is sent to the mobile phone APP.\nThis is a project completed while at JCU in Australia.\n","date":1532502725,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532502725,"objectID":"da86703006101c2350b81eb0bcb9ff17","permalink":"https://ruixu.netlify.app/project/arduino-based-automatic-soil-irrigation-system/","publishdate":"2018-07-25T07:12:05.657Z","relpermalink":"/project/arduino-based-automatic-soil-irrigation-system/","section":"project","summary":"Automatically control irrigation behavior and transmit data to mobile APP in real time","tags":["IoT","Hardware"],"title":"Arduino-based automatic soil irrigation system","type":"project"},{"authors":null,"categories":null,"content":"This project is concerned about CT system parameter calibration and imaging. First,a plane orthogonal coordinate system with the origin at the center of the ellipse is established. The analytical relationship between the length of the ray passing through the medium and the ray direction,the distance between the detector unit and the three parameters from the origin to the ray is given; Then the ratio of the information received by two adjacent receivers at each rotation is theoretically equal to the ratio of their corresponding rays through the length,using the receiver absorption information and the ratio of the corresponding ray to the length of the ray. Taking the least square error of the two values as the objective function, the nonlinear programming model is established to obtain the ray direction of the unit distance and rotation, and the parameters of the CT system are calibrated. In view of the reduction of receiver receiving information in CT system, a restoration model is established by using Radon inverse transform to solve and verify the intersection method of tangent area.\n","date":1506325137,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1506325137,"objectID":"0e711aaf199ea6cb0d1c8a67135d6764","permalink":"https://ruixu.netlify.app/project/ct-reconstruction/","publishdate":"2017-09-25T07:38:57.525Z","relpermalink":"/project/ct-reconstruction/","section":"project","summary":"Use optimized algorithm and Radon transform to complete the parameter calibration and imaging of a CT system","tags":["image resoration"],"title":"CT system parameter calibration and imaging","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://ruixu.netlify.app/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]